---
title: "Eviction Lab Data Exploration"
author: "Allison Shafer, Monica Puerto, Allison Ragan"
date: "12/4/2019"
output:
  pdf_document: default
  html_document: default
---
```{r knitr setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE,eval = TRUE,include = FALSE,fig.height = 12,fig.width = 8)

```


```{r setup, include=FALSE}

# call in libraries to use

suppressMessages(library(tidyverse))
suppressMessages(library(DataExplorer))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
suppressMessages(library(rvest))
suppressMessages(library(spData))
suppressMessages(library(tigris))
suppressMessages(library(sf))
suppressMessages(library(gridExtra))
suppressMessages(library(corrplot))
suppressMessages(library(factoextra))
suppressMessages(library(cluster))
suppressMessages(library(RColorBrewer))
suppressMessages(library(MASS))
suppressMessages(library(leaflet))
suppressMessages(library(spatialEco))
suppressMessages(library(sp))
suppressMessages(library(tmap))
suppressMessages(library(viridis))


```

# Introduction



# Data Downloads
```{r download data - eviction dataset}

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed
eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")

# check to see if URL saved to variable
head(eviction_US_all)

# download the csv file
download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min

# read the csv file into R and save into dataframe
eviction_US_all <- read_csv("./data/eviction_US_all.csv")

# replace "-" in column names 
names(eviction_US_all) <- gsub(x = names(eviction_US_all), pattern = "-", replacement = "_")  
```


```{r import rural}

# download and load rural classifications

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed 
urban_rural <- c("http://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx")

# download the .xlsx file
download.file(urban_rural, destfile = "./data/urban_rural.xlsx", mode = "wb")

# read xlsx into R
urban_rural <- read_excel(skip = 3, "./data/urban_rural.xlsx")

# clean data set
urban_rural <- urban_rural %>%
  rename("Percent_Rural" = "2010 Census \r\nPercent Rural",
         "GEOID" = "2015 GEOID") 

# create Rural Flag where rural percentage is greater than 50%
urban_rural <-urban_rural %>%
  mutate(rural_flag = ifelse(round(Percent_Rural, 3) > 50, 1, 0)) %>%
  dplyr::select(GEOID, State, Percent_Rural, rural_flag) 

```

```{r Webscrape US Labor Stats}

if(!file.exists("./data/labor_data")) {dir.create("./data/labor_data")}

# save url into a variable
url <- "https://www.bls.gov/lau/#tables"

# download the html content using read_html
download.file(url,destfile="./data/uslabor.html")
us_county_labor_html <- read_html("./data/uslabor.html")

# extract the xslx 
us_county_labor_html %>% 
   rvest::html_nodes("ul") %>%
        rvest::html_nodes("li") %>%
        rvest::html_nodes("a") %>%
        rvest::html_attr("href") %>%
        str_subset(".xlsx$") -> us_labor_urls

# domain
domain <- "https://www.bls.gov"

# paste domain to urls
str_c(domain,us_labor_urls) -> us_labor_urls

# only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)

# a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
  download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}

# save the files pertaining to us labor
labor_files <- dir("./data/labor_data")


# create a function that downloads each url and saves it #into a dataframe
read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}

# map the function to read each file 
map(labor_files,read_files) -> all_labor_data

# join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data

# remove some rows that have NA in Year and remove empty column next to year
filter(all_labor_data,!is.na(year)) %>% dplyr::select(-6) -> all_labor_data
```


``` {r small data transformations}
 
#creating a GEOID to join 
all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)
 
#change year to integer
all_labor_data$year <- as.integer(all_labor_data$year)
 
```

```{r make county dataset}
#County Table joined with 2 additional variables : rural flag and unemployment rate

eviction_county <- eviction_US_all %>%
  right_join(urban_rural, key = "GEOID") %>% 
  left_join(dplyr::select(all_labor_data,GEOID,year,unemployment_rate), by =c("GEOID" = "GEOID", "year"="year"))
         
```

```{r make state dataset}
# create state level eviction data

eviction_state <- eviction_US_all %>%
  filter(nchar(GEOID) == 2)
         
```

```{r make region column,warning=FALSE}

#creating state and region table
states_regions <- as.data.frame(cbind(state.name,levels(state.region)))
names(states_regions) <- c("states","region")
  
left_join(eviction_state, states_regions, by = c("name"="states")) -> eviction_state

left_join(eviction_county, states_regions,by = c("parent_location"="states")) -> eviction_county

#Need to replace DC with more logical region
eviction_county$region[eviction_county$name == "District of Columbia"] <- "South"

#remove rows with no region
eviction_county %>% drop_na(region) -> eviction_county
```

```{r make pct_non_white column for county}
eviction_county$pct_nonwhite <- 100 - eviction_county$pct_white
```

```{r removing 2009 and earlier and non continental US }
eviction_county_2010 <- eviction_county %>%
  filter(year >= 2010) %>%
  mutate(rural_flag = as.character(rural_flag)) %>%
  filter(!State %in% c('AK', 'HI'))

eviction_state_2010 <- eviction_state %>%
  filter(year >= 2010) %>%
  filter(!GEOID %in% c('02', '15', '60', '66', '69', '72', '78')) 
```

```{r Kmeans creating cluster}
km <- eviction_county_2010 %>%
  group_by(GEOID) %>%
  mutate(average_population = mean(population, na.rm = TRUE), 
         average_poverty_rate = mean(poverty_rate, na.rm = TRUE), 
         average_pct_renter_occupied = mean(pct_renter_occupied, na.rm = TRUE), 
         average_median_gross_rent = mean(median_gross_rent, na.rm = TRUE), 
         average_median_household_income = mean(median_household_income, na.rm = TRUE), 
         average_median_property_value = mean(median_property_value, na.rm = TRUE), 
         average_rent_burden = mean(rent_burden, na.rm = TRUE), 
         average_pct_white = mean(pct_white, na.rm = TRUE), 
         average_pct_af_am = mean(pct_af_am, na.rm = TRUE), 
         average_pct_hispanic = mean(pct_hispanic, na.rm = TRUE), 
         average_pct_am_ind = mean(pct_am_ind, na.rm = TRUE), 
         average_pct_asian = mean(pct_asian, na.rm = TRUE), 
         average_pct_nh_pi = mean(pct_nh_pi, na.rm = TRUE), 
         average_pct_multiple = mean(pct_multiple, na.rm = TRUE), 
         average_pct_other = mean(pct_other, na.rm = TRUE), 
         average_Percent_Rural = mean(Percent_Rural, na.rm = TRUE), 
         average_unemployment_rate = mean(unemployment_rate, na.rm = TRUE), 
         average_pct_nonwhite = mean(pct_nonwhite, na.rm = TRUE)) 
  #filter(State != "AK" & State != "HI")
km <- subset(km, select = c("GEOID", "average_population", "average_poverty_rate", "average_pct_renter_occupied", "average_median_gross_rent", "average_median_household_income", "average_median_property_value", "average_rent_burden", "average_pct_white", "average_pct_af_am", "average_pct_hispanic", "average_pct_am_ind", "average_pct_asian", "average_pct_nh_pi", "average_pct_multiple", "average_pct_other", "average_Percent_Rural", "average_unemployment_rate", "average_pct_nonwhite" ))
# dedupe and drop nulls
km <- km %>%
  distinct() %>% # reduces to 3147
  drop_na() # reduces to 3138
# set GEOID (chr.) to index
km <- km %>%
  column_to_rownames(., var = "GEOID")
km_sc <- km
# scale numerical data
ind <- sapply(km_sc, is.numeric)
km_sc[ind] <- lapply(km_sc[ind], scale)
# determine optimal clusters 
# elbow 
set.seed(123)
fviz_nbclust(km_sc, kmeans, method = "wss") # 3
# silhouette
fviz_nbclust(km_sc, kmeans, method = "silhouette") # 3
# Results
# Compute k-means clustering
# play around with methods and k amounts 
set.seed(123)
# Hartigan-Wong
hw_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Hartigan-Wong")
# hw_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Hartigan-Wong")
fviz_cluster(hw_km3, data = km_sc)
# fviz_cluster(hw_km4, data = km_sc)
# fviz_cluster(hw_km5, data = km_sc)
# fviz_cluster(hw_km6, data = km_sc)
# fviz_cluster(hw_km7, data = km_sc)
# Lloyd
# ll_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Lloyd")
# ll_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Lloyd")
# ll_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Lloyd")
# ll_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Lloyd")
# ll_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Lloyd")
# fviz_cluster(ll_km3, data = km_sc)
# fviz_cluster(ll_km4, data = km_sc)
# fviz_cluster(ll_km5, data = km_sc)
# fviz_cluster(ll_km6, data = km_sc)
# fviz_cluster(ll_km7, data = km_sc)
# # Forgy
# fg_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Forgy")
# fg_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Forgy")
# fg_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Forgy")
# fg_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Forgy")
# fg_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Forgy")
# fviz_cluster(fg_km3, data = km_sc)
# fviz_cluster(fg_km4, data = km_sc)
# fviz_cluster(fg_km5, data = km_sc)
# fviz_cluster(fg_km6, data = km_sc)
# fviz_cluster(fg_km7, data = km_sc)
# # MacQueen
# mq_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "MacQueen")
# mq_km4 <- kmeans(km_sc, 4, nstart = 25 , algorithm = "MacQueen")
# mq_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "MacQueen")
# mq_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "MacQueen")
# mq_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "MacQueen")
# fviz_cluster(mq_km3, data = km_sc)
# fviz_cluster(mq_km4, data = km_sc)
# fviz_cluster(mq_km5, data = km_sc)
# fviz_cluster(mq_km6, data = km_sc)
# fviz_cluster(mq_km7, data = km_sc)
 
# Extract clusters and add to data frame
km$cluster <- hw_km3$cluster
# km$hw_km4 <- hw_km4$cluster 
# km$hw_km5 <- hw_km5$cluster 
# km$hw_km6 <- hw_km6$cluster 
# km$hw_km7 <- hw_km7$cluster 
# km$ll_km3 <- ll_km3$cluster
# km$cluster <- ll_km4$cluster
# km$ll_km5 <- ll_km5$cluster
# km$ll_km6 <- ll_km6$cluster
# km$ll_km7 <- ll_km7$cluster
# km$fg_km3 <- fg_km3$cluster
# km$fg_km4 <- fg_km4$cluster
# km$fg_km5 <- fg_km5$cluster
# km$fg_km6 <- fg_km6$cluster
# km$fg_km7 <- fg_km7$cluster
# km$mq_km3 <- mq_km3$cluster
# km$mq_km4 <- mq_km4$cluster
# km$mq_km5 <- mq_km5$cluster
# km$mq_km6 <- mq_km6$cluster
# km$mq_km7 <- mq_km7$cluster

# reintroduce GEOID as column
km$GEOID <- c(row.names(km))
# reset index
rownames(km) <- NULL
km <- km %>%
  dplyr::select(GEOID, everything())

# make table of class counts
# thw_km3 <- table(km$hw_km3)
# thw_km4 <- table(km$hw_km4)
# thw_km5 <- table(km$hw_km5)
# thw_km6 <- table(km$hw_km6)
# thw_km7 <- table(km$hw_km7)
# tll_km3 <- table(km$ll_km3)
# tll_km4 <- table(km$ll_km4)
# tll_km5 <- table(km$ll_km5)
# tll_km6 <- table(km$ll_km6)
# tll_km7 <- table(km$ll_km7)
# tfg_km3 <- table(km$fg_km3)
# tfg_km4 <- table(km$fg_km4)
# tfg_km5 <- table(km$fg_km5)
# tfg_km6 <- table(km$fg_km6)
# tfg_km7 <- table(km$fg_km7)
# tmq_km3 <- table(km$mq_km3)
# tmq_km4 <- table(km$mq_km4)
# tmq_km5 <- table(km$mq_km5)
# tmq_km6 <- table(km$mq_km6)
# tmq_km7 <- table(km$mq_km7)
# 
# # the second and fourth 4 clusters seem to be the best options--more clusters, but less overlap
# km$cluster <- km$ll_km4 
```

```{r merge back Kmeans clusters to county dataset}
geo_clust <- subset(km, select = c("GEOID", "cluster"))
eviction_county_2010 <- merge(eviction_county_2010, geo_clust)
eviction_county_2010$cluster <- as.character(eviction_county_2010$cluster)
```

```{r write csvs to use for RShiny}

write_csv(eviction_county_2010,path = "./data/eviction_county_2010.csv")

write_csv(eviction_state_2010,path = "./data/eviction_state_2010.csv")
```

```{r download county spatial data}

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

#download county shapefiles
download.file("https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip", destfile = "./data/county_shp.zip")

spatial_data <- "./data/county_shp.zip"

unzip(spatial_data, overwrite = TRUE, exdir = "./eviction_by_state")

county_boundaries <- st_read("./data/spatial/county_shp/cb_2018_us_county_500k.shp")
```


# Data Exploration

```{r Chunk Nulls Exploration}
#We have 22.5% missing of eviction rate data in county and 11% missing in state. 
missing_state <- plot_missing(eviction_state)
missing_eviction <- plot_missing(eviction_county)
#colSums(is.na(eviction_state))/nrow(eviction_state)
#colSums(is.na(eviction_county))/nrow(eviction_county)
grid.arrange(missing_state,missing_eviction,ncol=2)

# Look at missing data from 2010 and beyond
missing_state_2010 <- plot_missing(eviction_state_2010)
missing_eviction_2010 <- plot_missing(eviction_county_2010)
#colSums(is.na(eviction_state))/nrow(eviction_state)
#colSums(is.na(eviction_county))/nrow(eviction_county)
grid.arrange(missing_state_2010, missing_eviction_2010, ncol=2)

```
```{r Check if any states missing evictions}
eviction_state %>% 
  group_by(GEOID,name) %>% 
  summarise_at(c("eviction_filings", "evictions"), sum, na.rm = TRUE) %>% 
  filter(evictions != 0)

# Check if any states missing eviction filing rates
eviction_state %>% 
  group_by(GEOID,name) %>% 
  summarise_at(c("eviction_filing_rate"), sum, na.rm = TRUE) %>% 
  filter(eviction_filing_rate != 0)
```

```{r Correlation Matrix}

#plot_correlation(na.omit(eviction_county), maxcat = 5L)
na.omit(eviction_county) %>%
select_if(is.numeric) %>%
  as.matrix() %>% cor()  -> cor_matrix


corrplot(cor_matrix[,1:nrow(cor_matrix)][1:nrow(cor_matrix),21, drop=FALSE], cl.pos='n',cl.ratio = .2, method = "number", tl.srt = 45,tl.col = "black")

#corrplot(cor_matrix, type="upper", order="hclust", sig.level = 0.01, insig = "blank")
```

```{r data exploration}

#look at col names
colnames(eviction_US_all)

#look at summary of data
summary(eviction_US_all)

summary(all_labor_data)

```

```{r EDA county - eviction rate}

# get top 100 counties with highest average eviction rate
eviction_county_2010 %>%
  group_by(GEOID) %>%
  summarise(
    avg_rate = mean(eviction_filing_rate, na.rm = TRUE)
  ) %>%
  top_n(100) %>%
  arrange(desc(avg_rate))


# histogram of eviction rates in county dataset
eviction_county_2010 %>%
  group_by(eviction_filing_rate) %>%
  count() %>%
  ggplot()+
  geom_histogram(aes(eviction_filing_rate))
  

```

```{r Distribution of Variables}
eviction_county %>%
  dplyr::select(-year,-eviction_filings, -evictions,-imputed, -low_flag,-subbed) %>% 
  keep(is.numeric) %>%                     # Keep only numeric columns
  gather() %>%                             # Convert to key-value pairs
  ggplot(aes(value)) +                     # Plot the values
    facet_wrap(~ key, scales = "free") +   # In separate panels
    geom_density() 
```

```{r EDA state level data}

# look at dataset

names(eviction_state_2010)

summary(eviction_state_2010)

# look at 2016 
eviction_state_2010 %>%
  filter(year == 2016) %>%
  ggplot(aes(x = reorder(name, eviction_filing_rate), y = eviction_filing_rate, 
             fill = rent_burden)) +
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  geom_bar(stat = 'identity', width = .75) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 7)) +
  ggtitle("Eviction Filing Rate by State") +
  labs(fill = "Percent Rent Burden") +
  ylab("Eviction Filing Rate") +
  xlab("State")

```


```{r gganimate eviction for state}

# look at eviction rate over time per state -- create gganimate

anim_eviction_state <- eviction_state_2010 %>%
  ggplot(aes(x = eviction_filing_rate, y = factor(name,
                                                  levels = rev(levels(factor(name)))))) +
  geom_point(aes(size = population, fill = rent_burden), 
             shape = 21) +
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  scale_x_log10(breaks = 2^(-1:7)*1000) +
  scale_size(range = c(1, 20), guide = FALSE) +
  labs(x = "Eviction Rate",
       y = "State",
       fill = "Percent Rent Burden") +
  transition_states(year, transition_length = 1,
                    state_length = 1)+
  ggtitle("Year showing {closest_state}",
          subtitle = "Frame {frame} of {nframes}")+
  theme_bw() 

anim_eviction_state

```

```{r gganimate eviction for county}

# look at eviction rate over time per top 25 counties -- create gganimate
# this needs to have better formatting for final.

# get top 25 counties with highest average eviction rate
county_top25_eviction <- eviction_county_2010 %>%
  group_by(GEOID) %>%
  summarise(
    avg_rate = mean(eviction_filing_rate, na.rm = TRUE)
  ) %>%
  top_n(25) %>%
  arrange(desc(avg_rate))

# add data for top 25 highest eviction filing rate
top25_counties <- county_top25_eviction %>%
  left_join(eviction_county_2010, by = "GEOID") %>%
  dplyr::select(everything()) %>%
  mutate(name_state = str_c(name,", ",State))


anim_evic_top25_counties <- top25_counties %>%
  ggplot(aes(x = eviction_filing_rate, y = factor(name_state,
                                                  levels = rev(levels(factor(name_state)))))) +
  geom_point(aes(size = population, fill = rent_burden),
             shape = 21) +
   scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  scale_x_log10(breaks = 2^(-1:7)*1000) +
  scale_size(range = c(1, 20), guide = FALSE) +
  labs(x = "Eviction Filing Rate",
       y = "County",
       fill = "Percent Rent Burden") +
  transition_states(year, transition_length = 1,
                    state_length = 1)+
  ggtitle("Year showing {closest_state}",
          subtitle = "Frame {frame} of {nframes}")+
  theme_bw()

anim_evic_top25_counties 
```

```{r county EDA}
top25_counties %>%
  group_by(parent_location, year) %>%
  count()

# what variables do the top 25 have in common
summary(top25_counties)

# get bottom 100 counties with lowest average eviction rate
county_top100_eviction <- eviction_county_2010 %>%
  group_by(GEOID) %>%
  summarise(
    avg_rate = mean(eviction_filing_rate, na.rm = TRUE)
  ) %>%
  top_n(100) %>%
  arrange(desc(avg_rate))

# add data for lowest 100 highest eviction filing rate
top100_counties <- county_top100_eviction %>%
  left_join(eviction_county_2010, by = "GEOID") %>%
  dplyr::select(everything()) %>%
  mutate(name_state = str_c(name,", ",State))

summary(top100_counties)

ggplot(top100_counties, aes(x = pct_renter_occupied, y = eviction_filing_rate)) +
  geom_point(aes(col = State)) +
  ggtitle("Eviction Filing Rate vs. Percent Renter Occupied
  for Counties With Lowest Eviction Filing Rate")

# get bottom 100 counties with lowest average eviction rate
county_btm100_eviction <- eviction_county_2010 %>%
  group_by(GEOID) %>%
  summarise(
    avg_rate = mean(eviction_filing_rate, na.rm = TRUE)
  ) %>%
  top_n(-100) %>%
  arrange(desc(avg_rate))

# add data for lowest 100 highest eviction filing rate
btm100_counties <- county_btm100_eviction %>%
  left_join(eviction_county_2010, by = "GEOID") %>%
  dplyr::select(everything()) %>%
  mutate(name_state = str_c(name,", ",State))

summary(btm100_counties)

ggplot(btm100_counties, aes(x = pct_renter_occupied, y = eviction_filing_rate)) +
  geom_point(aes(col = State)) +
  ggtitle("Eviction Filing Rate vs. Percent Renter Occupied
  for Counties With Lowest Eviction Filing Rate")

```

# Set up Spatial Datasets for Mapping
```{r setup spatial datasets - county level}

# add spatial data to the county level eviction data
sp_eviction_county <- county_boundaries %>%
                      left_join(eviction_county_2010, c("GEOID" = "GEOID"))

# ensure spatial data was added
sp_eviction_county

# create field for average filing rate and keep only entities in the continental US
filing_by_county <- sp_eviction_county %>%
                     group_by(GEOID) %>%
                     summarise(avg_filing_rate = mean(eviction_filing_rate, 
                                                      na.rm = TRUE))
# look at fields in dataset
names(filing_by_county)

# merge field into eviction_county table
filing_avg_county <- merge(filing_by_county, eviction_county_2010, by = "GEOID")

# look at fields in dataset
names(filing_avg_county)

# create a table with all field averages.
county_all_avgs <- filing_avg_county %>%
                            group_by(GEOID) %>%
                            summarise_if(is.numeric, mean, na.rm = TRUE) %>%
                            mutate_at(2:28, funs(round(., 0)))

# confirm dataset is spatial
county_all_avgs

```

```{r EDA state eviction data}
eviction_state_2010 %>%
  filter(is.na(eviction_filing_rate))


eviction_state_2010 %>%
  filter(is.na(pct_renter_occupied))

```
```{r EDA county}

```

```{r set up spatial datasets - state level}

# test reading in csv
eviction_by_state <- eviction_state_2010

# create spatial datasets for state
state_us_geo <- tigris::states(class= "sf")

#convert to a SpatialPolygonDataFrame
spatial_state <- as_Spatial(state_us_geo)


#Join in state eviction data
state_eviction <- sp::merge(spatial_state, eviction_by_state, by = c("GEOID" = "GEOID"), duplicateGeoms = TRUE)

as.data.frame(state_eviction) %>%
  arrange(STATEFP) %>%
  filter(name == "South Dakota") %>%
  arrange(year)

#Remove NAs for mapping application
#state_eviction <- sp.na.omit(state_eviction, col.name = )

```

```{r Create grouped spatial data tables for analysis}

# Create average filing rate by state table
filing_by_state <- state_us_geo %>%
                   right_join(eviction_state_2010, by = "GEOID") %>%
                    group_by(GEOID) %>%
                    summarise(avg_filing_rate = mean(eviction_filing_rate, 
                                                      na.rm = TRUE))
# merge new field into table
filing_avg_state <- merge(filing_by_state, eviction_state_2010,  by="GEOID")

# create averages for all numeric fields in dataset
state_all_avgs <- filing_avg_state %>%
                            group_by(GEOID) %>%
                            summarise_if(is.numeric, mean, na.rm = TRUE) %>%
                            mutate_at(2:26, funs(round(., 0)))

# Create state name field
state_names <- eviction_state_2010 %>%
                group_by(GEOID, name) %>%
                dplyr::select(GEOID, name) %>%
                distinct()


# Add state name field into table             
state_all_avgs <- state_all_avgs %>%
  left_join(state_names, by = "GEOID") %>%
  dplyr::select(GEOID, name, everything()) 


df_allavg_st <- as.data.frame(state_all_avgs)
df_allavg_st
```

```{r}
state_all_avgs %>%
  ggplot(aes(x = reorder(name, eviction_filing_rate), y = eviction_filing_rate, 
             fill = rent_burden)) +
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  geom_bar(stat = 'identity', width = .7) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 6)) +
  ggtitle("Average Eviction Filing Rate by State") +
  labs(fill = "Percent Rent Burden") +
  ylab("Average Eviction Filing Rate") +
  xlab("State")

```

```{r create data breaks for symbology- state map}

pretty_breaks <- c(5, 10, 15, 20, 25, 65)
# find the extremes
minVal <- min(state_all_avgs$avg_filing_rate, na.rm = T)
# compute labels
labels <- c()
brks <- c(minVal, pretty_breaks)
# round the labels (actually, only the extremes)
for(idx in 1:length(brks)){
  labels <- c(labels,round(brks[idx + 1], 2))
}

labels <- labels[1:length(labels)-1]
# define a new variable on the data set just as above
state_all_avgs$brks <- cut(state_all_avgs$avg_filing_rate, 
                     breaks = brks, 
                     include.lowest = TRUE, 
                     labels = labels)

brks_scale <- levels(state_all_avgs$brks)
labels_scale <- rev(brks_scale)

state_all_avgs$brks

state_all_avgs$geometry

```

```{r ggplot for static maps}

# map eviction filing rate by state

ggplot(data = state_all_avgs) +
  geom_sf(aes(fill = brks), color = "black", lwd = 0.03) +
  coord_sf(crs = st_crs(102003)) +
  theme(legend.position = "bottom") +
  scale_fill_manual(values = rev(viridis(6)), 
                  breaks = rev(brks_scale), 
                  labels = labels_scale, 
                  name = "Average Eviction Filing Rate", 
                  guide = guide_legend(
                        direction = "horizontal",
                        keyheight = unit(2, units = "mm"),
                        keywidth = unit(70 / length(labels), units = "mm"),
                        title.position = 'top',
                        title.hjust = 0.5,
                        label.hjust = 1,
                        nrow = 1,
                        byrow = T,
                        reverse = T,
                        label.position = "bottom")) +
  ggtitle("Average Eviction Filing Rate by State") +
  theme(panel.grid.major = element_line(colour = 'transparent'),
        plot.title = element_text(hjust = 0.5),
  axis.title.x=element_blank(), 
  axis.text.x=element_blank(),
  axis.ticks.x=element_blank(),
  axis.title.y=element_blank(), 
  axis.text.y=element_blank(),
  axis.ticks.y=element_blank(),
  panel.background=element_blank(),
  panel.border=element_blank(),
  panel.grid.minor=element_blank(),
  plot.background=element_blank())

```

```{r static county map - set up}

pretty_breaks <- c(5, 10, 20, 30, 40, 50, 110)
# find the extremes
minVal <- min(county_all_avgs$avg_filing_rate, na.rm = T)
maxVal <- max(county_all_avgs$avg_filing_rate, na.rm = T)

# compute labels
labels <- c()
brks <- c(minVal, pretty_breaks)
# round the labels (actually, only the extremes)
for(idx in 1:length(brks)){
  labels <- c(labels,round(brks[idx + 1], 2))
}

labels <- labels[1:length(labels)-1]
# define a new variable on the data set just as above
county_all_avgs$brks <- cut(county_all_avgs$avg_filing_rate, 
                     breaks = brks, 
                     include.lowest = TRUE, 
                     labels = labels)

brks_scale <- levels(county_all_avgs$brks)
labels_scale <- rev(brks_scale)

```

```{r map county averages}

ggplot(data = county_all_avgs) +
  geom_sf(aes(fill = brks), color = "black", lwd = 0.01) +
  coord_sf(crs = st_crs(102003)) +
  theme(legend.position = "bottom") +
  scale_fill_manual(values = rev(viridis(8)), 
                  breaks = rev(brks_scale), 
                  labels = labels_scale, 
                  name = "Average Eviction Filing Rate", 
                  guide = guide_legend(
                        direction = "horizontal",
                        keyheight = unit(2, units = "mm"),
                        keywidth = unit(70 / length(labels), units = "mm"),
                        title.position = 'top',
                        title.hjust = 0.5,
                        label.hjust = 1,
                        nrow = 1,
                        byrow = T,
                        reverse = T,
                        label.position = "bottom")) +
  ggtitle("Average Eviction Filing Rate by County") +
  theme(panel.grid.major = element_line(colour = 'transparent'),
        plot.title = element_text(hjust = 0.5),
  axis.title.x=element_blank(), 
  axis.text.x=element_blank(),
  axis.ticks.x=element_blank(),
  axis.title.y=element_blank(), 
  axis.text.y=element_blank(),
  axis.ticks.y=element_blank(),
  panel.background=element_blank(),
  panel.border=element_blank(),
  panel.grid.minor=element_blank(),
  plot.background=element_blank())

```

```{r}
names(state_eviction)

```

```{r Create Mapping Application Function}
# Create color schemes
purPal <- colorBin("Reds", domain = state_eviction$eviction_filing_rate, bins = c(0, 5, 10, 20, 30, 40, 50, 100, 120))
blugr <- colorBin("YlGnBu", domain = state_eviction$pct_renter_occupied, n = 6)

# Create popup messages
popup_evic <- paste0("<b>","<center>", state_eviction$name,
                     "</b>","</center>",
                     "<br />Median HH Income: $", state_eviction$median_household_income,
                     "<br />Population: ", state_eviction$population,
                     "<br />Percent Rent Burden: ", state_eviction$rent_burden,
                     "<br />Eviction Filing Rate: ", state_eviction$eviction_filing_rate)
#popup_evic

# Create mapping function
map_maker <- function(x){
  if (x == "Eviction Filing Rates") {
  leaflet() %>% 
  setView(-98.483330, 38.712046, zoom = 4) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = state_eviction, fillColor = ~purPal(state_eviction$eviction_filing_rate), 
              smoothFactor = 0.2, fillOpacity = .7, weight = 0.2,
              popup = ~popup_evic) %>%
  addLegend(purPal,
             values = state_eviction$eviction_filing_rate,
             position = "bottomleft",
             title = "Eviction Filing Rates")
  }else{
  leaflet() %>% 
  setView(-98.483330, 38.712046, zoom = 4) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data = state_eviction, 
              fillColor = ~blugr(state_eviction$pct_renter_occupied),
              smoothFactor = 0.2, fillOpacity = .7, weight = 0.2,
              popup = ~popup_evic) %>%
  addLegend(blugr,
             values = state_eviction$pct_renter_occupied,
             position = "bottomleft",
             title = "Percent Renter Occupied") }
}
  
x <- "Eviction Filing Rates"
map_maker(x)

```

