---
title: "Eviction Lab Data Exploration"
author: "Allison Shafer, Monica Puerto, Allison Ragan"
date: "12/4/2019"
output:
  pdf_document: default
  html_document: default
---
```{r knitr setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE,eval = TRUE,include = FALSE,fig.height = 12,fig.width = 8)

```


```{r setup, include=FALSE}

# call in libraries to use

suppressMessages(library(tidyverse))
suppressMessages(library(DataExplorer))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
suppressMessages(library(tmap))
suppressMessages(library(spData))
suppressMessages(library(tigris))
suppressMessages(library(sf))
suppressMessages(library(gridExtra))
suppressMessages(library(corrplot))
suppressMessages(library(factoextra))
suppressMessages(library(cluster))
suppressMessages(library(RColorBrewer))
suppressMessages(library(MASS))
suppressMessages(library(ggcorrplot))
```

# Intro



# Data Downloads
```{r download data - eviction dataset}

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed - right click on excel symbol and select
# copy link address
eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")

# check to see if URL saved to variable
eviction_US_all

#download the csv file
download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min

# read the csv file into R and save into dataframe
eviction_US_all <- read_csv("./data/eviction_US_all.csv")

#replacing "-" in column names
names(eviction_US_all) <- gsub(x = names(eviction_US_all), pattern = "-", replacement = "_")  
```

```{r import rural urban}

# download and load urbal/rural classifications

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed - right click on excel symbol and select
# copy link address
urban_rural <- c("http://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx")

#download the .xlsx file

download.file(urban_rural, destfile = "./data/urban_rural.xlsx", mode = "wb")

#read xlsx into R

urban_rural <- read_excel(skip = 3, "./data/urban_rural.xlsx")


# clean data set
urban_rural <- urban_rural %>%
  rename("Percent_Rural" = "2010 Census \r\nPercent Rural",
         "GEOID" = "2015 GEOID")


# create Rural Flag where Ruran Percentage is greater than 50%
urban_rural <-urban_rural %>%
  mutate(rural_flag = ifelse(round(Percent_Rural, 3) > 50, 1, 0)) %>%
  dplyr::select(GEOID, State, Percent_Rural, rural_flag)

```

```{r Webscrape US Labor Stats}
if(!file.exists("./data/labor_data")) {dir.create("./data/labor_data")}

#save url into a variable
url <- "https://www.bls.gov/lau/#tables"

#download the html content using read_html
download.file(url,destfile="./data/uslabor.html")
us_county_labor_html <- read_html("./data/uslabor.html")

#extract the xslx
us_county_labor_html %>%
   rvest::html_nodes("ul") %>%
        rvest::html_nodes("li") %>%
        rvest::html_nodes("a") %>%
        rvest::html_attr("href") %>%
        str_subset(".xlsx$") -> us_labor_urls

#domain
domain <- "https://www.bls.gov"

#paste domain to urls
str_c(domain,us_labor_urls) -> us_labor_urls

#only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)

#a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
  download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}

#save the files pertaining to us labor
labor_files <- dir("./data/labor_data")


#create a function that downloads each url and saves it #into a dataframe
read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}

#map the function to read each file
map(labor_files,read_files) -> all_labor_data

#join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data

#remove some rows that have NA in Year and remove empty column next to year
filter(all_labor_data,!is.na(year)) %>% dplyr::select(-6) -> all_labor_data
```


``` {r small data transformations}

#creating a GEOID to join
all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)

#change year to integer
all_labor_data$year <- as.integer(all_labor_data$year)

```


```{r download county spatial data}

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

#download county shapefiles
download.file("https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip", destfile = "./data/county_shp.zip")

spatial_data <- "./data/county_shp.zip"

unzip(spatial_data, overwrite = TRUE, exdir = "./data/spatial/county_shp")

county_boundaries <- st_read("./data/spatial/county_shp/cb_2018_us_county_500k.shp")


```


```{r make county dataset}
#County Table joined with 2 additional variables : rural flag and unemployment rate

eviction_county <- eviction_US_all %>%
  right_join(urban_rural, key = "GEOID") %>%
  left_join(dplyr::select(all_labor_data,GEOID,year,unemployment_rate), by =c("GEOID" = "GEOID", "year"="year"))

```

```{r make state dataset}

eviction_state <- eviction_US_all %>%
  filter(nchar(GEOID) == 2)


```

```{r make region column,warning=FALSE}
states_regions <- as.data.frame(cbind("states"= state.name,"region"=state.region))#creating state and region table
#names(states_regions) <- c("states","region")
#recode regions
region_names <- c("1" = "Northeast", "2" = "South", "3" = "North Central","4"="West")
recode(states_regions$region, !!!region_names) -> states_regions$region

left_join(eviction_state, states_regions, by = c("name"="states")) -> eviction_state

left_join(eviction_county, states_regions,by = c("parent_location"="states")) -> eviction_county

#dplyr::select(eviction_county,parent_location,region) %>% unique() #check if joined right
#Need to replace DC with a region
eviction_county$region[eviction_county$name == "District of Columbia"] <- "South"

#remove rows with no region
eviction_county %>% drop_na(name) -> eviction_county
```

```{r make pct_non_white column for county}
eviction_county$pct_nonwhite <- 100 - eviction_county$pct_white
```


```{r removing 2009 and earlier and non continental US }
eviction_county_2010 <- eviction_county %>%
  filter(year >= 2010) %>%
  mutate(rural_flag = as.character(rural_flag)) %>%
  filter(!State %in% c('AK', 'HI'))

eviction_state_2010 <- eviction_state %>%
  filter(year >= 2010) %>%
  filter(!GEOID %in% c('02', '15', '60', '66', '69', '72', '78'))
```

```{r Kmeans creating cluster}
km <- eviction_county_2010 %>%
  group_by(GEOID) %>%
  mutate(average_population = mean(population, na.rm = TRUE),
         average_poverty_rate = mean(poverty_rate, na.rm = TRUE),
         average_pct_renter_occupied = mean(pct_renter_occupied, na.rm = TRUE),
         average_median_gross_rent = mean(median_gross_rent, na.rm = TRUE),
         average_median_household_income = mean(median_household_income, na.rm = TRUE),
         average_median_property_value = mean(median_property_value, na.rm = TRUE),
         average_rent_burden = mean(rent_burden, na.rm = TRUE),
         average_pct_white = mean(pct_white, na.rm = TRUE),
         average_pct_af_am = mean(pct_af_am, na.rm = TRUE),
         average_pct_hispanic = mean(pct_hispanic, na.rm = TRUE),
         average_pct_am_ind = mean(pct_am_ind, na.rm = TRUE),
         average_pct_asian = mean(pct_asian, na.rm = TRUE),
         average_pct_nh_pi = mean(pct_nh_pi, na.rm = TRUE),
         average_pct_multiple = mean(pct_multiple, na.rm = TRUE),
         average_pct_other = mean(pct_other, na.rm = TRUE),
         average_Percent_Rural = mean(Percent_Rural, na.rm = TRUE),
         average_unemployment_rate = mean(unemployment_rate, na.rm = TRUE),
         average_pct_nonwhite = mean(pct_nonwhite, na.rm = TRUE))
  #filter(State != "AK" & State != "HI")
km <- subset(km, select = c("GEOID", "average_population", "average_poverty_rate", "average_pct_renter_occupied", "average_median_gross_rent", "average_median_household_income", "average_median_property_value", "average_rent_burden", "average_pct_white", "average_pct_af_am", "average_pct_hispanic", "average_pct_am_ind", "average_pct_asian", "average_pct_nh_pi", "average_pct_multiple", "average_pct_other", "average_Percent_Rural", "average_unemployment_rate", "average_pct_nonwhite" ))
# dedupe and drop nulls
km <- km %>%
  distinct() %>% # reduces to 3147
  drop_na() # reduces to 3138
# set GEOID (chr.) to index
km <- km %>%
  column_to_rownames(., var = "GEOID")
km_sc <- km
# scale numerical data
ind <- sapply(km_sc, is.numeric)
km_sc[ind] <- lapply(km_sc[ind], scale)
# determine optimal clusters
# elbow
set.seed(123)
fviz_nbclust(km_sc, kmeans, method = "wss") # 3
# silhouette
fviz_nbclust(km_sc, kmeans, method = "silhouette") # 3
# Results
# Compute k-means clustering
# play around with methods and k amounts
set.seed(123)
# Hartigan-Wong
hw_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Hartigan-Wong")
# hw_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Hartigan-Wong")
# # hw_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Hartigan-Wong")
fviz_cluster(hw_km3, data = km_sc)
# fviz_cluster(hw_km4, data = km_sc)
# fviz_cluster(hw_km5, data = km_sc)
# fviz_cluster(hw_km6, data = km_sc)
# fviz_cluster(hw_km7, data = km_sc)
# Lloyd
# ll_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Lloyd")
# ll_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Lloyd")
# ll_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Lloyd")
# ll_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Lloyd")
# ll_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Lloyd")
# fviz_cluster(ll_km3, data = km_sc)
# fviz_cluster(ll_km4, data = km_sc)
# fviz_cluster(ll_km5, data = km_sc)
# fviz_cluster(ll_km6, data = km_sc)
# fviz_cluster(ll_km7, data = km_sc)
# # Forgy
# fg_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "Forgy")
# fg_km4 <- kmeans(km_sc, 4, nstart = 25, algorithm = "Forgy")
# fg_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "Forgy")
# fg_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "Forgy")
# fg_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "Forgy")
# fviz_cluster(fg_km3, data = km_sc)
# fviz_cluster(fg_km4, data = km_sc)
# fviz_cluster(fg_km5, data = km_sc)
# fviz_cluster(fg_km6, data = km_sc)
# fviz_cluster(fg_km7, data = km_sc)
# # MacQueen
# mq_km3 <- kmeans(km_sc, 3, nstart = 25, algorithm = "MacQueen")
# mq_km4 <- kmeans(km_sc, 4, nstart = 25 , algorithm = "MacQueen")
# mq_km5 <- kmeans(km_sc, 5, nstart = 25, algorithm = "MacQueen")
# mq_km6 <- kmeans(km_sc, 6, nstart = 25, algorithm = "MacQueen")
# mq_km7 <- kmeans(km_sc, 7, nstart = 25, algorithm = "MacQueen")
# fviz_cluster(mq_km3, data = km_sc)
# fviz_cluster(mq_km4, data = km_sc)
# fviz_cluster(mq_km5, data = km_sc)
# fviz_cluster(mq_km6, data = km_sc)
# fviz_cluster(mq_km7, data = km_sc)

# Extract clusters and add to data frame
km$cluster <- hw_km3$cluster
# km$hw_km4 <- hw_km4$cluster
# km$hw_km5 <- hw_km5$cluster
# km$hw_km6 <- hw_km6$cluster
# km$hw_km7 <- hw_km7$cluster
# km$ll_km3 <- ll_km3$cluster
# km$cluster <- ll_km4$cluster
# km$ll_km5 <- ll_km5$cluster
# km$ll_km6 <- ll_km6$cluster
# km$ll_km7 <- ll_km7$cluster
# km$fg_km3 <- fg_km3$cluster
# km$fg_km4 <- fg_km4$cluster
# km$fg_km5 <- fg_km5$cluster
# km$fg_km6 <- fg_km6$cluster
# km$fg_km7 <- fg_km7$cluster
# km$mq_km3 <- mq_km3$cluster
# km$mq_km4 <- mq_km4$cluster
# km$mq_km5 <- mq_km5$cluster
# km$mq_km6 <- mq_km6$cluster
# km$mq_km7 <- mq_km7$cluster

# reintroduce GEOID as column
km$GEOID <- c(row.names(km))
# reset index
rownames(km) <- NULL
km <- km %>%
  dplyr::select(GEOID, everything())

# make table of class counts
# thw_km3 <- table(km$hw_km3)
# thw_km4 <- table(km$hw_km4)
# thw_km5 <- table(km$hw_km5)
# thw_km6 <- table(km$hw_km6)
# thw_km7 <- table(km$hw_km7)
# tll_km3 <- table(km$ll_km3)
# tll_km4 <- table(km$ll_km4)
# tll_km5 <- table(km$ll_km5)
# tll_km6 <- table(km$ll_km6)
# tll_km7 <- table(km$ll_km7)
# tfg_km3 <- table(km$fg_km3)
# tfg_km4 <- table(km$fg_km4)
# tfg_km5 <- table(km$fg_km5)
# tfg_km6 <- table(km$fg_km6)
# tfg_km7 <- table(km$fg_km7)
# tmq_km3 <- table(km$mq_km3)
# tmq_km4 <- table(km$mq_km4)
# tmq_km5 <- table(km$mq_km5)
# tmq_km6 <- table(km$mq_km6)
# tmq_km7 <- table(km$mq_km7)
#
# # the second and fourth 4 clusters seem to be the best options--more clusters, but less overlap
# km$cluster <- km$ll_km4
```

```{r merge back Kmeans clusters to county dataset}
geo_clust <- subset(km, select = c("GEOID", "cluster"))
eviction_county_2010 <- merge(eviction_county_2010, geo_clust)
eviction_county_2010$cluster <- as.character(eviction_county_2010$cluster)

# Add county name column
eviction_county_2010$county_state <- str_c(tools::toTitleCase(as.character(eviction_county_2010$name)),
                                           eviction_county_2010$parent_location, sep = ", ")
```

```{r creating spatial datasets for state}

# get Census TIGER shapefiles for state
state_us_geo <- tigris::states(class= "sf")


# add spatial data to the state level eviction data

eviction_by_state <- eviction_state_2010 %>%
                    left_join(state_us_geo, c("GEOID" = "GEOID")) %>%
                    dplyr::select(-LSAD, -MTFCC, -FUNCSTAT, -STUSPS, -STATENS)

```

```{r write csvs}
write_csv(eviction_by_state,path = "./data/eviction_by_state.csv")
write_csv(eviction_county_2010,path = "./data/eviction_county_2010.csv")
```


# Data Exploration

```{r Chunk Nulls Exploration}
#We have 22.5% missing of eviction rate data in county and 11% missing in state. ALl
missing_state <- plot_missing(eviction_state_2010)
missing_eviction <- plot_missing(eviction_county_2010)
#colSums(is.na(eviction_state_2010))/nrow(eviction_state_2010)
#colSums(is.na(eviction_county_2010))/nrow(eviction_county_2010)
grid.arrange(missing_state,missing_eviction,ncol=2)
```



```{r Check if any states missing Evictions}
eviction_state_2010 %>% group_by(GEOID,name) %>% summarise_at(c("eviction_filings", "evictions"), sum, na.rm = TRUE) %>% filter(evictions == 0)
```



```{r Correlation Matrix}


#plot_correlation(na.omit(eviction_county), maxcat = 5L)
na.omit(eviction_county_2010) %>%
filter(year>2009) %>%
mutate(GEOID = as.numeric(GEOID)) %>%
select_if(is.numeric) %>%
group_by(GEOID) %>%
  summarise_all(mean,na.rm=TRUE) %>%
  as.matrix() %>% cor()  -> cor_matrix

#corrplot1

corrplot(cor_matrix[,1:nrow(cor_matrix)][1:nrow(cor_matrix),21, drop=FALSE], cl.pos='n',cl.ratio = .2, method = "number", tl.srt = 45,tl.col = "black",col = spectral[1:4],tl.cex = .8)

#corrplot 2
corrplot(cor_matrix, type="upper", order="hclust", sig.level = 0.01, insig = "blank",tl.srt = 45,tl.col = "black",cl.ratio = .2,tl.cex = .4)

#corrplot 3
ggcorrplot(cor_matrix[,1:nrow(cor_matrix)][1:nrow(cor_matrix),22, drop=FALSE], sig.level=0.05, lab_size = 4.5, p.mat = NULL,
           insig = c("pch", "blank"), pch = 1, pch.col = "black", pch.cex =1,
           tl.cex = 8) +
  theme(axis.text.x = element_text(margin=margin(-2,0,0,0)),  # Order: top, right, bottom, left
        axis.text.y = element_text(margin=margin(0,-2,0,0)))
```



```{r data exploration}

#look at col names
colnames(eviction_US_all)

#look at summary of data
summary(eviction_US_all)

summary(all_labor_data)

```

```{r EDA county - eviction rate}

# get top 100 counties with highest average evistion rate
eviction_county_2010 %>%
  group_by(GEOID) %>%
  summarise(
    avg_rate = mean(eviction_filing_rate, na.rm = TRUE)
  ) %>%
  top_n(100) %>%
  arrange(desc(avg_rate))


# histogram of eviction rates in county dataset
eviction_county_2010 %>%
  group_by(eviction_filing_rate) %>%
  count() %>%
  ggplot(aes(eviction_filing_rate)) +
  geom_histogram()

```



```{r Distribution of Variables}
eviction_county_2010 %>%
  dplyr::select(-year,-eviction_filings, -evictions,-imputed, -low_flag,-subbed) %>%
  mutate(GEOID = as.numeric(GEOID)) %>%
  keep(is.numeric) %>%
  group_by(GEOID) %>%
  dplyr::select(-GEOID) %>%
  # Keep only numeric columns
  summarise_all(mean,na.rm=TRUE) %>%
  gather() %>%                             # Convert to key-value pairs
  ggplot(aes(value)) +                     # Plot the values
    facet_wrap(~ key, scales = "free") +   # In separate panels
    geom_density(fill=spectral[1]) +
  theme_minimal() +
  ggtitle("Distribution of Variables Eviction Data 2010-2016")
```




```{r gganimate eviction for state}

# look at eviction rate over time per state -- create gganimate
# this needs to have better formatting for final.

eviction_state_2010 %>%
  ggplot(aes(x = eviction_filing_rate, y = name)) +
  geom_point(aes(size = population, fill = rent_burden),
             shape = 21) +
  scale_x_log10(breaks = 2^(-1:7)*1000) +
  scale_size(range = c(1, 20), guide = FALSE) +
  labs(x = "Eviction Rate",
       y = "State") +
  transition_states(year, transition_length = 1,
                    state_length = 1)+
  ggtitle("Year showing {closest_state}",
          subtitle = "Frame {frame} of {nframes}")+
  theme_bw()
```


```{r Region Trend Eviction Filing Rate}

dplyr::select(eviction_county_2010, region,eviction_filing_rate, year) %>%
  #filter(year>2009) %>%
  group_by(year,region) %>%
  summarise_all(mean,na.rm=TRUE) %>%
  ggplot(aes(year,eviction_filing_rate,color = region)) +
  geom_line() +
  scale_x_continuous(breaks=seq(2009,2016,1)) +
  theme_minimal() +
  ggtitle("Average Regional Eviction Filing Rate by year") +
  scale_color_brewer(palette = "Spectral")

dplyr::select(eviction_county_2010, region,eviction_filing_rate, year) %>%
  filter(year > 2010) %>% #have to have even amount of years
  na.omit() %>%
  mutate(year_bin = ifelse(year > 2014,"y2014_2016","y2011_2013")) %>%
  dplyr::select(region,year_bin, eviction_filing_rate) %>%
  group_by(region,year_bin) %>%
  summarise_all(mean,na.rm=TRUE) %>%
  pivot_wider(names_from = "year_bin",values_from = "eviction_filing_rate") %>%
  mutate(delta = y2014_2016 - y2011_2013) %>%
  ggplot(aes(region,delta,fill=delta)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  scale_color_brewer(palette = "Spectral") +
  ggtitle("Average Eviction Delta of 2014-2016 vs 2011-2013")

```

```{r}
delta_diverse_region <- dplyr::select(eviction_county_2010, region,eviction_filing_rate, year, pct_nonwhite) %>%
  filter(year > 2010 & pct_nonwhite > 50) %>% #have to have even amount of years
  na.omit() %>%
  mutate(year_bin = ifelse(year > 2014,"y2014_2016","y2011_2013")) %>%
  dplyr::select(region,year_bin, eviction_filing_rate) %>%
  group_by(region,year_bin) %>%
  summarise_all(mean,na.rm=TRUE) %>%
  pivot_wider(names_from = "year_bin",values_from = "eviction_filing_rate") %>%
  mutate(delta = y2014_2016 - y2011_2013) %>%
  ggplot(aes(region,delta,fill=delta)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  scale_color_brewer(palette = "Spectral") +
  ggtitle("Average Eviction Delta of 2014-2016 vs 2011-2013 with higher diversity")

```

```{r}
delta_non_diverse_region <- dplyr::select(eviction_county_2010, region,eviction_filing_rate, year, pct_nonwhite) %>%
  filter(year > 2010 & pct_nonwhite < 50) %>% #have to have even amount of years
  na.omit() %>%
  mutate(year_bin = ifelse(year > 2014,"y2014_2016","y2011_2013")) %>%
  dplyr::select(region,year_bin, eviction_filing_rate) %>%
  group_by(region,year_bin) %>%
  summarise_all(mean,na.rm=TRUE) %>%
  pivot_wider(names_from = "year_bin",values_from = "eviction_filing_rate") %>%
  mutate(delta = y2014_2016 - y2011_2013) %>%
  ggplot(aes(region,delta,fill=delta)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  scale_color_brewer(palette = "Spectral") +
  ggtitle("Average Eviction Delta of 2014-2016 vs 2011-2013 with less diversity")

grid.arrange(delta_diverse_region,delta_non_diverse_region)
```

```{r}
dplyr::select(eviction_county_2010,cluster,eviction_filing_rate,region) %>%
  na.omit()%>%
  ggplot(aes(y=eviction_filing_rate,x=cluster)) +
  geom_boxplot(aes(fill=cluster)) +
  ylim(0,50) +
  scale_color_brewer(palette = "Spectral") +
  theme_minimal() +
  ggtitle("Dispersion of Eviction Filing Rate among clusters") +
  facet_wrap(~region)
```
