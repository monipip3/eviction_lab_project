---
title: "DS_Project"
author: "Allison Shafer, Monica Puerto, Alison Ragan"
date: "10/27/2019"
output: html_document
---

```{r setup, include=FALSE}

# call in libraries to use

suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
```


```{r download data}
start = Sys.time()
# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed - right click on excel symbol and select 
# copy link address
eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")

# check to see if URL saved to variable
eviction_US_all

#download the csv file

download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min

# read the csv file into R and save into dataframe

eviction_US_all <- read_csv("./data/eviction_US_all.csv")

eviction_US_all
end <- Sys.time()

print(end-start)
```

```{r rural urban}

# download and load urbal/rural classifications

# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}

# store urls needed - right click on excel symbol and select 
# copy link address
urban_rural <- c("http://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx")

#download the .xlsx file

download.file(urban_rural, destfile = "./data/urban_rural.xlsx", mode = "wb")

#read xlsx into R

urban_rural <- read_excel(skip = 3, "./data/urban_rural.xlsx")

names(urban_rural)

# clean data set
urban_rural <- urban_rural %>%
  rename("Percent_Rural" = "2010 Census \r\nPercent Rural",
         "GEOID" = "2015 GEOID") 

# check names were updated
names(urban_rural)

# select only needed fields
urban_rural <-urban_rural %>%
  mutate(rural_flag = ifelse(round(Percent_Rural, 3) > 50, 1, 0)) %>%
  select(GEOID, State, Percent_Rural, rural_flag) 


# view cleaned up dataset
urban_rural


```

```{r Webscrape US Labor Stats}
setwd("/Users/monicapuerto/Desktop/Github/eviction_lab_project")

start <- Sys.time()
if(!file.exists("./data/labor_data")) {dir.create("./data/labor_data")}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(rvest))

#save url into a variable
url <- "https://www.bls.gov/lau/#tables"

#download the html content using read_html
download.file(url,destfile="./data/uslabor.html")
us_county_labor_html <- read_html("./data/uslabor.html")

#extract the xslx 
us_county_labor_html %>% 
   rvest::html_nodes("ul") %>%
        rvest::html_nodes("li") %>%
        rvest::html_nodes("a") %>%
        rvest::html_attr("href") %>%
        str_subset(".xlsx$") -> us_labor_urls

#domain
domain <- "https://www.bls.gov"

#paste domain to urls
str_c(domain,us_labor_urls) -> us_labor_urls

#only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)

#a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
  download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}
#save the files pertaining to us labor
labor_files <- dir("./data/labor_data")
#create a function that downloads each url and saves it #into a dataframe

read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}

#map the function to read each file 
map(labor_files,read_files) -> all_labor_data

#join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data

#remove some rows that have NA in Year and remove emoty column next to year
filter(all_labor_data,!is.na(year)) %>% select(-X__1) -> all_labor_data
 
 end<- Sys.time()

 
 print(end-start)
 
 #creating a GEOID to join 
 all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)
 
#change year to integer
 all_labor_data$year <- as.integer(all_labor_data$year)
 
```


```{r data exploration, echo = false, eval = false}

#look at col names
colnames(eviction_US_all)

#look at unique values for each variable
map(eviction_US_all, unique)


```

```{r make county dataset}
#County Table joined with 2 additional variables : rural flag and unemployment rate
eviction_county <- eviction_US_all %>%
  right_join(urban_rural, key = "GEOID") %>% 
  left_join(select(all_labor_data,GEOID,year,unemployment_rate), by =c("GEOID" = "GEOID", "year"="year"))
         
eviction_county 

```

```{r make state dataset}

eviction_state <- eviction_US_all %>%
  filter(nchar(GEOID) == 2)
         
eviction_state

```

```{r make place dataset}

eviction_place <- eviction_US_all %>%
  filter(nchar(GEOID) == 7)
         
eviction_place

```

```{r EDA state level data}

# look at dataset

names(eviction_state)

summary(eviction_state)

eviction_state %>%
  filter(year == 2016) %>%
  ggplot(aes(x = name, y = `poverty-rate`)) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r EDA county level data}

# look at data set
eviction_county

ncol(eviction_county)

summary(eviction_county)

glimpse(eviction_county)

eviction_county %>%
  group_by(GEOID) %

```

```{r}

ggplot(eviction_state, aes(`eviction-rate`, evictions, size = population)) +
  geom_point(alpha = 0.7, show.legend = FALSE) +
  scale_size(range = c(2, 12)) +
  scale_x_log10() +
  facet_wrap(~ name) +
  # Here comes the gganimate specific bits
  labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +
  transition_states(year) +
  ease_aes('linear')

```

```{r map attempt}
data("county_laea", package = "tidycensus")

data("state_laea", package = "tidycensus")
```