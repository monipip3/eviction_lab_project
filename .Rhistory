#only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)
#a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}
#save the files pertaining to us labor
labor_files <- dir("./data/labor_data")
#create a function that downloads each url and saves it #into a dataframe
read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}
#map the function to read each file
map(labor_files,read_files) -> all_labor_data
#join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data
#remove some rows that have NA in Year and remove emoty column next to year
# DOES NOT WORK
# filter(all_labor_data,!is.na(year)) %>% select(-X__1) -> all_labor_data
end<- Sys.time()
print(end-start)
#creating a GEOID to join
all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)
#change year to integer
all_labor_data$year <- as.integer(all_labor_data$year)
#look at col names
colnames(eviction_US_all)
#look at unique values for each variable
# map(eviction_US_all, unique)
# call in libraries to use
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
# install.packages("gganimate")
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
# install.packages("gifski")
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
# install.packages("visdat")
suppressMessages(library(visdat))
# install.packages("Amelia")
suppressMessages(library(Amelia))
# start = Sys.time()
# # set up a data directory if it does not exist already
# if(!file.exists("./data")) {dir.create("./data")}
# # store urls needed - right click on excel symbol and select
# # copy link address
# eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")
# # check to see if URL saved to variable
# eviction_US_all
# #download the csv file
# download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min
# read the csv file into R and save into dataframe
eviction_US_all <- read_csv("./data/eviction_US_all.csv")
eviction_US_all
end <- Sys.time()
print(end-start)
# call in libraries to use
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
# install.packages("gganimate")
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
# install.packages("gifski")
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
# install.packages("visdat")
suppressMessages(library(visdat))
# install.packages("Amelia")
suppressMessages(library(Amelia))
# start = Sys.time()
# # set up a data directory if it does not exist already
# if(!file.exists("./data")) {dir.create("./data")}
# # store urls needed - right click on excel symbol and select
# # copy link address
# eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")
# # check to see if URL saved to variable
# eviction_US_all
# #download the csv file
# download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min
# read the csv file into R and save into dataframe
eviction_US_all <- read_csv("./data/eviction_US_all.csv")
eviction_US_all
end <- Sys.time()
print(end-start)
setwd("~/Dropbox/Learning/School/Grad/Semesters/2019 Fall/STAT 613 Data Science/Project/eviction_lab_project")
# download and load urbal/rural classifications
# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}
# store urls needed - right click on excel symbol and select
# copy link address
urban_rural <- c("http://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx")
#download the .xlsx file
download.file(urban_rural, destfile = "./data/urban_rural.xlsx", mode = "wb")
#read xlsx into R
urban_rural <- read_excel(skip = 3, "./data/urban_rural.xlsx")
names(urban_rural)
# clean data set
urban_rural <- urban_rural %>%
rename("Percent_Rural" = "2010 Census \r\nPercent Rural",
"GEOID" = "2015 GEOID")
# check names were updated
names(urban_rural)
# select only needed fields
urban_rural <-urban_rural %>%
mutate(rural_flag = ifelse(round(Percent_Rural, 3) > 50, 1, 0)) %>%
select(GEOID, State, Percent_Rural, rural_flag)
# view cleaned up dataset
urban_rural
start <- Sys.time()
if(!file.exists("./data/labor_data")) {dir.create("./data/labor_data")}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(rvest))
#save url into a variable
url <- "https://www.bls.gov/lau/#tables"
#download the html content using read_html
download.file(url,destfile="./data/uslabor.html")
us_county_labor_html <- read_html("./data/uslabor.html")
#extract the xslx
us_county_labor_html %>%
rvest::html_nodes("ul") %>%
rvest::html_nodes("li") %>%
rvest::html_nodes("a") %>%
rvest::html_attr("href") %>%
str_subset(".xlsx$") -> us_labor_urls
#domain
domain <- "https://www.bls.gov"
#paste domain to urls
str_c(domain,us_labor_urls) -> us_labor_urls
#only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)
#a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}
#save the files pertaining to us labor
labor_files <- dir("./data/labor_data")
#create a function that downloads each url and saves it #into a dataframe
read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}
#map the function to read each file
map(labor_files,read_files) -> all_labor_data
#join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data
#remove some rows that have NA in Year and remove emoty column next to year
# DOES NOT WORK
# filter(all_labor_data,!is.na(year)) %>% select(-X__1) -> all_labor_data
end<- Sys.time()
print(end-start)
#creating a GEOID to join
all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)
#change year to integer
all_labor_data$year <- as.integer(all_labor_data$year)
#look at col names
colnames(eviction_US_all)
#look at unique values for each variable
# map(eviction_US_all, unique)
# County Table joined with 2 additional variables : rural flag and unemployment rate
eviction_county <- eviction_US_all %>%
right_join(urban_rural, key = "GEOID") %>%
left_join(select(all_labor_data,GEOID,year,unemployment_rate), by=c("GEOID" = "GEOID", "year"="year"))
eviction_county
eviction_state <- eviction_US_all %>%
filter(nchar(GEOID) == 2)
eviction_state
eviction_place <- eviction_US_all %>%
filter(nchar(GEOID) == 7)
eviction_place
# look at dataset
names(eviction_state)
summary(eviction_state)
eviction_state %>%
filter(year == 2016) %>%
ggplot(aes(x = name, y = `poverty-rate`)) +
geom_bar(stat = 'identity') +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# look at data set
eviction_county
ncol(eviction_county)
summary(eviction_county)
glimpse(eviction_county)
eviction_county %>%
group_by(GEOID) %>%
filter(year == 2016, `parent-location`=="Mississippi", `poverty-rate`>=15.49) %>%
ggplot(aes(x = name, y = `poverty-rate`)) +
geom_bar(stat = 'identity') +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# How much data is missing from each df?
# missmap(all_labor_data) # 9%
# missmap(eviction_county) # 3%
# missmap(eviction_place) # 10%
# missmap(eviction_state) # 1%
# missmap(eviction_US_all) #
# missmap(urban_rural) #
# what variables are associated with eviction rate?
# data is likely missing at random
# need to pick variables to use for KNN -- need those to predict eviction rate
# poverty rate? rent burden? population? renter-pop?
cor(eviction_state)
# what variables are associated with eviction rate?
# data is likely missing at random
# need to pick variables to use for KNN -- need those to predict eviction rate
# poverty rate? rent burden? population? renter-pop?
cor(eviction_state$`eviction-rate`)
sum(is.na(eviction_state))/sum(eviction_state)
sum(is.na(eviction_US_all$`eviction-rate`))
library(DataExplorer)
plot_missing(eviction_US_all)
# call in libraries to use
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
# install.packages("gganimate")
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
# install.packages("gifski")
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
# install.packages("visdat")
suppressMessages(library(visdat))
# what variables are associated with eviction rate?
# data is likely missing at random
# need to pick variables to use for KNN -- need those to predict eviction rate
# poverty rate? rent burden? population? renter-pop?
# cor(eviction_state$`eviction-rate`)
# sum(is.na(eviction_US_all$`eviction-rate`))
library(DataExplorer)
plot_missing(all_labor_data) #
plot_missing(eviction_county) #
plot_missing(eviction_place) #
plot_missing(eviction_state) #
plot_missing(eviction_US_all) #
plot_missing(urban_rural) #
plot_intro(eviction_county)
# call in libraries to use
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
# install.packages("gganimate")
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
# install.packages("gifski")
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
# install.packages("visdat")
suppressMessages(library(visdat))
suppressMessages(library(DataExplorer))
suppressMessages(library(gridExtra))
# what variables are associated with eviction rate?
# data is likely missing at random
# need to pick variables to use for KNN -- need those to predict eviction rate
# poverty rate? rent burden? population? renter-pop?
# cor(eviction_state$`eviction-rate`)
# sum(is.na(eviction_US_all$`eviction-rate`))
plot_missing(eviction_county) # 22.58%
plot_missing(eviction_place) # 23.9%
plot_missing(eviction_state) # 11.42%
plot_missing(eviction_US_all) # 21.86%
plot_missing(eviction_county) # 22.58%
ggplot(eviction_county, aes(x = unemployment_rate, y = eviction-rate)) + geom_point()
ggplot(eviction_county, aes(x = unemployment_rate, y = `eviction-rate`)) + geom_point()
ggplot(eviction_county, aes(x = unemployment_rate, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
library(corrplot)
library(RColorBrewer)
M <-cor(eviction_county)
corrplot(M, type="upper", order="hclust",
col=brewer.pal(n=8, name="RdYlBu"))
plot_histogram(eviction_county)
plot_density(eviction_county)
plot_correlation(eviction_county)
plot_bar(eviction_county)
plot_boxplot(eviction_county)
plot_boxplot(eviction_county, by = state)
names(eviction_county)
plot_boxplot(eviction_county, by = `parent-location`)
plot_boxplot(eviction_county, by = State)
plot_scatterplot(eviction_county, by = `eviction-rate`)
plot_scatterplot(eviction_county, by = `eviction.rate`)
plot_scatterplot(eviction_county, by = eviction.rate)
names(eviction_county)
plot_scatterplot(eviction_county, by = eviction_county$GEOID)
plot_scatterplot(eviction_county, by = eviction_county$year)
plot_scatterplot(eviction_county, by = year)
names(eviction_county)
ggplot(eviction_county, aes(x = year, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x) + geom_title("Year vs Eviction Rate")
# call in libraries to use
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))
suppressMessages(library(lubridate))
suppressMessages(library(stringr))
suppressMessages(library(purrr))
# install.packages("gganimate")
suppressMessages(library(gganimate))
suppressMessages(library(readxl))
# install.packages("gifski")
suppressMessages(library(gifski))
suppressMessages(library(tidycensus))
suppressMessages(library(rvest))
# install.packages("visdat")
suppressMessages(library(visdat))
# install.packages("DataExplorer")
suppressMessages(library(DataExplorer))
suppressMessages(library(gridExtra))
# start = Sys.time()
# # set up a data directory if it does not exist already
# if(!file.exists("./data")) {dir.create("./data")}
# # store urls needed - right click on excel symbol and select
# # copy link address
# eviction_US_all <- c("https://eviction-lab-data-downloads.s3.amazonaws.com/US/all.csv")
# # check to see if URL saved to variable
# eviction_US_all
# #download the csv file
# download.file(eviction_US_all, destfile = "./data/eviction_US_all.csv", mode = "wb") #this takes a bit ranges from 2-5 minutes, over bad WIFI might take 10 min
# read the csv file into R and save into dataframe
eviction_US_all <- read_csv("./data/eviction_US_all.csv")
eviction_US_all
end <- Sys.time()
print(end-start)
# remove '-' from column names
# for (i in names(eviction_US_all)) {
#   if (grepl("-", i, fixed=TRUE)) {
#     names(eviction_US_all) <- gsub("-", "_", i)
#   }
# }
#
# # write a function to replace dashes with underscores in column names
# dashes_to_unders <- function(df) {
#   for (i in names(df)) {
#     if (grepl("-", i, fixed=TRUE)) {
#       names(df) <- gsub("-", "_", i)
#     }
#   }
# }
# download and load urbal/rural classifications
# set up a data directory if it does not exist already
if(!file.exists("./data")) {dir.create("./data")}
# store urls needed - right click on excel symbol and select
# copy link address
urban_rural <- c("http://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx")
#download the .xlsx file
download.file(urban_rural, destfile = "./data/urban_rural.xlsx", mode = "wb")
#read xlsx into R
urban_rural <- read_excel(skip = 3, "./data/urban_rural.xlsx")
names(urban_rural)
# clean data set
urban_rural <- urban_rural %>%
rename("Percent_Rural" = "2010 Census \r\nPercent Rural",
"GEOID" = "2015 GEOID")
# check names were updated
names(urban_rural)
# select only needed fields
urban_rural <-urban_rural %>%
mutate(rural_flag = ifelse(round(Percent_Rural, 3) > 50, 1, 0)) %>%
select(GEOID, State, Percent_Rural, rural_flag)
# view cleaned up dataset
urban_rural
start <- Sys.time()
if(!file.exists("./data/labor_data")) {dir.create("./data/labor_data")}
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(rvest))
#save url into a variable
url <- "https://www.bls.gov/lau/#tables"
#download the html content using read_html
download.file(url,destfile="./data/uslabor.html")
us_county_labor_html <- read_html("./data/uslabor.html")
#extract the xslx
us_county_labor_html %>%
rvest::html_nodes("ul") %>%
rvest::html_nodes("li") %>%
rvest::html_nodes("a") %>%
rvest::html_attr("href") %>%
str_subset(".xlsx$") -> us_labor_urls
#domain
domain <- "https://www.bls.gov"
#paste domain to urls
str_c(domain,us_labor_urls) -> us_labor_urls
#only need years from 2000 to 2016
us_labor_urls[3:19] -> us_labor_2000_2016
years <- rep(2000:2016,1)
#a for loop that downloads each file
for(i in seq_along(us_labor_2000_2016)){
download.file(us_labor_2000_2016[i],destfile = paste("./data/labor_data/",years[i],".xslx",sep=""),mode="wb")
}
#save the files pertaining to us labor
labor_files <- dir("./data/labor_data")
#create a function that downloads each url and saves it #into a dataframe
read_files <- function(x){
read_excel(path= paste("./data/labor_data/",x,sep=""),skip = 7,col_names = c("laus_code","state_fips_code","county_fips_code","county_name","year","","labor_force","employed","unemployed","unemployment_rate"),sheet = 1,na="")
}
#map the function to read each file
map(labor_files,read_files) -> all_labor_data
#join all the US labor tables
all_labor_data %>% reduce(full_join) -> all_labor_data
#remove some rows that have NA in Year and remove emoty column next to year
# DOES NOT WORK
# filter(all_labor_data,!is.na(year)) %>% select(-X__1) -> all_labor_data
end<- Sys.time()
print(end-start)
#creating a GEOID to join
all_labor_data$GEOID <- str_c(all_labor_data$state_fips_code,all_labor_data$county_fips_code)
#change year to integer
all_labor_data$year <- as.integer(all_labor_data$year)
#look at col names
colnames(eviction_US_all)
#look at unique values for each variable
# map(eviction_US_all, unique)
# County Table joined with 2 additional variables : rural flag and unemployment rate
eviction_county <- eviction_US_all %>%
right_join(urban_rural, key = "GEOID") %>%
left_join(select(all_labor_data,GEOID,year,unemployment_rate), by=c("GEOID" = "GEOID", "year"="year"))
eviction_county
eviction_state <- eviction_US_all %>%
filter(nchar(GEOID) == 2)
eviction_state
eviction_place <- eviction_US_all %>%
filter(nchar(GEOID) == 7)
eviction_place
# look at dataset
names(eviction_state)
summary(eviction_state)
eviction_state %>%
filter(year == 2016) %>%
ggplot(aes(x = name, y = `poverty-rate`)) +
geom_bar(stat = 'identity') +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# look at data set
eviction_county
ncol(eviction_county)
summary(eviction_county)
glimpse(eviction_county)
eviction_county %>%
group_by(GEOID) %>%
filter(year == 2016, `parent-location`=="Mississippi", `poverty-rate`>=15.49) %>%
ggplot(aes(x = name, y = `poverty-rate`)) +
geom_bar(stat = 'identity') +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# data("county_laea", package = "tidycensus")
# data("state_laea", package = "tidycensus")
# 23% of county df missing eviction rate
plot_missing(eviction_county) # 22.58%
plot_missing(eviction_place) # 23.9%
plot_missing(eviction_state) # 11.42%
plot_missing(eviction_US_all) # 21.86%
plot_density(eviction_county)
ggplot(eviction_county, aes(x = unemployment_rate, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x) + geom_title("Unemployment Rate vs Eviction Rate")
plot_density(eviction_county)
ggplot(eviction_county, aes(x = unemployment_rate, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = year, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x) + geom_title("Year vs Eviction Rate")
plot_density(eviction_county)
ggplot(eviction_county, aes(x = unemployment_rate, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = year, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
names(eviction_county)
ggplot(eviction_county, aes(x = population, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = `poverty-rate`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = `rent-burder`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = `rent-burden`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
names(eviction_county)
introduce(eviction_county)
plot_bar(eviction_county)
plot_correlation(na.omit(eviction_county), maxcat = 5L)
names(eviction_county)
ggplot(eviction_county, aes(x = `Percent_Rural`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
plot_correlation(na.omit(eviction_county), maxcat = 5L)
plot_str(eviction_county)
?plot_correlation
plot_correlation(na.omit(eviction_county), maxcat = 5L, 'eviction-rate')
plot_bar(eviction_county)
create_report(eviction_county)
names(eviction_county)
ggplot(eviction_county, aes(x = `pct-white`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
ggplot(eviction_county, aes(x = `pct-asian`, y = `eviction-rate`)) + geom_point() + geom_smooth(method='lm',formula=y~x)
?knn.impute
?knn
library(DMwR)
install.packages("DMwR")
library(DMwR)
knnOutput <- knnImputation(eviction_county[, !names(eviction_county) %in% "eviction-rate"])
?knn.impute
?knn
data(khanmiss)
khan.expr <- khanmiss[-1, -(1:2)]
?impute.knn
impute.knn(eviction_county, k=3, rng.seed=18)
library(impute)
install.packages("impute")
?impute
impute.knn(eviction_county, k=3, rng.seed=18)
library(impute)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("impute")
library(impute)
impute.knn(eviction_county, k=3)
knn <- subset(eviction_county, select = -c(year))
names(eviction_county)
